/*
 * -------------------------------------------------
 *  nanowgs Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

/* 
 * pipeline input parameters 
 */
params {
  genomeref           = "/staging/leuven/stg_00002/lcb/jdemeul/reference/chm13_v1.1_chrY_KI270740_EBV/indexes/minimap2-ont/genome.fa"
  // genomerefindex      = "${file(params.genomeref).getParent()}/${file(params.genomeref).getBaseName()}_map-ont.mmi"
  // fastqs              = "/staging/leuven/stg_00002/lcb/jdemeul/projects/2020_fiberseq/data/20210503_S2_2folddilser_100kto3k_nano-gTag/20210503_1530_MN34250_AGI654_ad1ed051/fastq_pass/barcode06/"
  ont_base_dir        = "/staging/leuven/stg_00002/lcb/jdemeul/projects/2021_ASAP/data/raw/testsample/20210719_ASA_Edin_BA24_14_18/"
  guppy_gpu           = true
  min_read_qscore     = 10
  sampleid            = "ASA_Edin_BA24_14_18_chr20"
  outdir              = "./nanowgs_out_${params.sampleid}"
  tracedir            = "${params.outdir}/pipeline_info"
  sv_min_support      = 8
  sv_min_mapq         = 10
  sv_min_size         = 30
  sv_merge_max_dist   = 1000
  megalodon_model     = "res_dna_r941_min_modbases-all-context_v001.cfg"
  medaka_snp_model    = "r941_prom_sup_snp_g507"
  medaka_polish_model = "r941_prom_sup_g507"
  guppy_config        = "dna_r9.4.1_450bps_sup_prom.cfg"
  // rerio_base          = "/staging/leuven/stg_00002/lcb/jdemeul/software/rerio/basecall_models/"
  // guppy_barcode_kit   = "/staging/leuven/stg_00002/lcb/jdemeul/software/rerio/basecall_models/"
  with_gpu            = true
  gpu_devices         = "all"
  rebasecall          = false
  processed_reads     = ""
  aligned_sam         = ""
  aligned_bam         = ""
  shasta_config       = "/staging/leuven/stg_00002/lcb/jdemeul/software/shasta/conf/Nanopore-Sep2020.conf"
}

// Global default params, used in configs
workDir = '/scratch/leuven/302/vsc30235/nextflow'

// Process parameters
params.max_memory          = 160.GB
params.max_cpus            = 36
params.max_time            = 168.h
// 160 GB 36 cores 168h are max on VSC

// Profiles
profiles {
  debug       { process.beforeScript = 'echo $HOSTNAME' }
  docker      {
    enabled = true
    runOptions = '-u \$(id -u):\$(id -g)'
  }
  singularity {
    singularity.enabled = true
    singularity.autoMounts = true
    singularity.cacheDir = "/staging/leuven/stg_00002/lcb/jdemeul/software/singularity_images/"
    singularity.runOptions = '--cleanenv -H $PWD -B /lustre1,/staging,/data,${VSC_SCRATCH},${TMPDIR},${VSC_SCRATCH}/tmp:/tmp'
  }
  qsub {
    process.clusterOptions = "-A lp_symbiosys"
    process.executor = 'pbs'
  }
}

// Manifest info
manifest {
  name = 'nanowgs'
  author = 'Jonas Demeulemeester'
  homePage = 'https://github.com/jdemeul/nanowgs'
  description = 'A pipeline to analyse Nanopore WGS data'
  mainScript = 'main.nf'
  nextflowVersion = '>=19.10.0'
  version = '0.0.1'
}


process {

  // cpus   = { check_max( 8 * task.attempt, 'cpus' ) }
  // memory = { check_max( 32.GB * task.attempt, 'memory' ) }
  // time   = { check_max( 1.h * task.attempt, 'time' ) }

  errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
  maxRetries    = 1
  maxErrors     = '-1'

  // Process-specific resource requirements
  withLabel: cpu_low {
    cpus   = { check_max( 8 * task.attempt, 'cpus' ) }
  }
  withLabel: cpu_mid {
    cpus   = { check_max( 18 * task.attempt, 'cpus' ) }
  }
  withLabel: cpu_high {
    cpus   = { check_max( 36 * task.attempt, 'cpus' ) }
  }

  withLabel: mem_low {
    memory   = { check_max( 32.GB * task.attempt, 'memory' ) }
  }
  withLabel: mem_mid {
    memory   = { check_max( 64.GB * task.attempt, 'memory' ) }
  }
  withLabel: mem_high {
    memory   = { check_max( 160.GB * task.attempt, 'memory' ) }
  }

  withLabel: time_low {
    time   = { check_max( 1.h * task.attempt, 'time' ) }
  }
  withLabel: time_mid {
    time   = { check_max( 24.h * task.attempt, 'time' ) }
  }
  withLabel: time_high {
    time   = { check_max( 168.h * task.attempt, 'time' ) }
  }

  withLabel: with_gpus {
      // numgpus = 1
      // numppn = numgpus * 4
      // numthreads = numppn * 8
      // clusterOptions = '-l nodes=1:ppn=32:gpus=8:cascadelake -l partition=gpu -l pmem=20gb -A lp_symbiosys -l walltime=24:00:00'
      clusterOptions = '-l nodes=1:ppn=16:gpus=4:cascadelake -l partition=gpu -l pmem=20gb -A lp_symbiosys -l walltime=24:00:00'
      // For debugging:
      // clusterOptions = '-l nodes=1:ppn=9:gpus=1 -l partition=gpu -l walltime=00:15:00 -l qos=debugging -A lp_symbiosys'
      // Alternatively, older P100 architecture can be specified on the VSC
      // clusterOptions = '-l nodes=1:ppn=18:gpus=2:skylake -l partition=gpu -l pmem=5gb  -A lp_symbiosys -l walltime=168:00:00'
       maxForks = 1
       containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }

  withLabel: with_p100 {
      clusterOptions = '-l nodes=1:ppn=9:gpus=1:skylake -l partition=gpu -l pmem=5gb -A lp_symbiosys -l walltime=24:00:00'
       maxForks = 1
       containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }


  withLabel: bigmem {
      //  numanodes = 2
      //  lprocs = numanodes * 14
      //  numthreads = lprocs * 4
       clusterOptions = '-L tasks=1:lprocs=28:place=numanode=2 -l walltime=24:00:00 -l partition=superdome -q qsuperdome -A lp_symbiosys'
      //  queue = "qsuperdome"
       maxForks = 1
  }

  withLabel: bigmemnode {
       clusterOptions = 'qsub -l nodes=1:ppn=36  -l pmem=20gb  -l partition=bigmem -A lp_symbiosys -l walltime=24:00:00'
       maxForks = 1
  }

  withLabel:minimap {
    container = 'zeunas/minimap2:2.22'
  }
  withLabel:samtools {
    container = 'zeunas/samtools:1.13'
  } 
  withLabel:lra {
    container = 'zeunas/lra:1.3.2'
  }  
  withLabel:cutesv {
    container = 'zeunas/cutesv:1.0.11'
  }
  withLabel:sniffles {
    container = 'zeunas/sniffles:4ff6ecb'
  }
  withLabel:svim {
    container = 'zeunas/svim:2.0.0'
  }
  withLabel:survivor {
    container = 'zeunas/survivor:ed1ca51'
  }
  // withLabel:deepvariant {
  //   container = 'kishwars/pepper_deepvariant:r0.5-gpu'
  // }
  withLabel:pepper {
    container = 'kishwars/pepper_deepvariant:r0.4.1'
  }
  withLabel:shasta {
    container = 'zeunas/shasta-docker:latest'
  }
  withLabel:quast {
    container = 'zeunas/quast:5.1.0rc1'
  }
  withLabel:megalodon {
    container = 'zeunas/guppy:5.0.11-megalodon_v2.3.4'
  }
  withLabel:medaka {
    container = 'zeunas/medaka:1.4.3'
  }
  withLabel:bcftools {
    container = 'zeunas/bcftools:1.13'
  }
  withLabel:guppy {
    container = 'zeunas/guppy:5.0.11'
  }
  withLabel:fastp {
    container = 'zeunas/fastp:0.20.1'
  }
  withLabel:racon {
    container = 'zeunas/racon:v1.4.21-b591b12'
  }

}


// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      // return params.max_cpus as int
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}